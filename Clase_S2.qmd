---
title: "Comparación de Algoritmos de Clasificación con Validación Cruzada"
subtitle: "Curso: Minería de Datos – Unidad 3"
format: revealjs
revealjs:
  theme: simple
  slide-number: true
  toc: true
  incremental: true
jupyter: python3
---

## Universidad X · Facultad Y · Carrera Z  
### Integrantes del grupo  

<img src="logo_universidad.png" alt="Logo" style="height:120px;">  

## Introducción (1 / 3)

- **Propósito del trabajo**: comparar el desempeño de diversos algoritmos de *aprendizaje supervisado* usando un dataset económico real.  
- **Metodología**: validación cruzada (*k*-fold) y ajuste de hiperparámetros mediante *Grid Search*.  
- **Herramientas**: `pandas`, `scikit-learn`, `matplotlib`.

## Introducción (2 / 3) — ¿Aprendizaje supervisado?

> Entrenamos un modelo con datos etiquetados $(\mathbf X, y)$ para predecir la etiqueta de observaciones nuevas.

- **Regresión**: $y$ continua.  
- **Clasificación**: $y$ discreta.  
- **Nuestro caso**: clasificación binaria (`Nivel_IPC ∈ {0,1}`).

## Introducción (3 / 3) — Algoritmos utilizados

| Algoritmo | Idea clave |
|-----------|------------|
| **SVM** | Máximo margen entre clases. |
| **K‑NN** | Etiqueta según los *k* vecinos más cercanos. |
| **Gaussian Naive Bayes** | Probabilidades con independencia de atributos. |
| **MLP (Red neuronal)** | Capas densas que aprenden representaciones no lineales. |

## Variables y tipo de problema

```{python}
import pandas as pd

df = pd.read_csv("dataset_economico.csv", header=None,
                 names=["IPC", "Tipo_Cambio"])

df["IPC"] = pd.to_numeric(df["IPC"], errors="coerce")
df["Tipo_Cambio"] = pd.to_numeric(df["Tipo_Cambio"], errors="coerce")
df["Nivel_IPC"] = (df["IPC"] > 3).astype(int)
X = df[["Tipo_Cambio", "IPC"]]
y = df["Nivel_IPC"]
X.head()
```

::: incremental
- **Variable dependiente**: `Nivel_IPC` (0 = bajo, 1 = alto).  
- **Variables independientes**: `Tipo_Cambio`, `IPC` (continuas).  
- Al ser dicotómica, corresponde un **problema de clasificación**.
:::

## Tiempo de entrenamiento por algoritmo

```{python}
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
import time, pandas as pd

kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
models = {
    "SVM": Pipeline([("scaler", StandardScaler()), ("clf", SVC())]),
    "KNN": Pipeline([("scaler", StandardScaler()), ("clf", KNeighborsClassifier())]),
    "GNB": Pipeline([("scaler", StandardScaler()), ("clf", GaussianNB())]),
    "MLP": Pipeline([("scaler", StandardScaler()), ("clf", MLPClassifier(max_iter=500))])
}

rows = []
for name, pipe in models.items():
    t0 = time.time()
    GridSearchCV(pipe, {}, cv=kf).fit(X, y)
    rows.append([name, round(time.time()-t0, 3)])

pd.DataFrame(rows, columns=["Modelo", "Tiempo (s)"])
```

## Inferencia de coeficientes — Regresión logística (baseline)

```{python}
import statsmodels.api as sm
logit = sm.Logit(y, sm.add_constant(X)).fit(disp=False)
logit.summary2().tables[1]
```

## Gaussian Naive Bayes — Parámetros del modelo

```{python}
from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB().fit(X, y)
print("Medias (theta):", gnb.theta_)
print("Varianzas (sigma):", gnb.sigma_)
```

## Red neuronal — Arquitectura óptima

```{python}
from sklearn.neural_network import MLPClassifier
mlp_best = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42).fit(X, y)
print(mlp_best)
```

## Comparación de desempeño y mejores hiperparámetros

```{python}
param_grids = {
    "SVM": {"clf__C": [0.1, 1, 10], "clf__kernel": ["linear", "rbf"]},
    "KNN": {"clf__n_neighbors": [3, 5, 7]},
    "GNB": {"clf__var_smoothing": [1e-9, 1e-8, 1e-7]},
    "MLP": {"clf__hidden_layer_sizes": [(5,), (10,), (5, 5)]}
}

results = []
for name, base in models.items():
    grid = GridSearchCV(base, param_grids[name], cv=kf, scoring="accuracy")
    grid.fit(X, y)
    results.append([name, grid.best_score_, grid.best_params_])

pd.DataFrame(results, columns=["Modelo", "Accuracy CV", "Best Params"])
```

## Validación final con conjunto de prueba

```{python}
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
summary = []
for name, pipe in models.items():
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    pr, rc, f1, _ = precision_recall_fscore_support(y_test, y_pred, average="binary", zero_division=0)
    summary.append([name, acc, pr, rc, f1])

pd.DataFrame(summary, columns=["Modelo", "Accuracy", "Precision", "Recall", "F1"])
```

## Matriz de confusión y Curva ROC — GaussianNB

```{python}
from sklearn.metrics import confusion_matrix, RocCurveDisplay
import seaborn as sns

gnb_best = GaussianNB(var_smoothing=1e-8).fit(X_train, y_train)
cm = confusion_matrix(y_test, gnb_best.predict(X_test))
plt.figure(figsize=(4,3))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusión – GNB");
```

```{python}
RocCurveDisplay.from_estimator(gnb_best, X_test, y_test);
```

## Conclusiones

- **GaussianNB**: entrenamiento casi instantáneo y rendimiento competitivo.  
- **SVM**/ **KNN**: mayor *accuracy* pero tiempos de cómputo superiores.  
- **MLP**: sin mejora notable con solo dos atributos; requiere más variables.  
- La validación cruzada estratificada aseguró estimaciones robustas.

## Referencias (≥ 6)

1. Géron, A. *Hands‑On Machine Learning with Scikit‑Learn, Keras & TensorFlow* (O’Reilly, 2022).  
2. Pedregosa, F. *et al.* “Scikit‑learn: Machine Learning in Python”, *JMLR* 12 (2011).  
3. Murphy, K. P. *Machine Learning: A Probabilistic Perspective* (MIT Press, 2012).  
4. Bishop, C. M. *Pattern Recognition and Machine Learning* (Springer, 2006).  
5. James, G., Witten, D., Hastie, T. & Tibshirani, R. *An Introduction to Statistical Learning* (Springer, 2021).  
6. Friedman, J., Hastie, T. & Tibshirani, R. *The Elements of Statistical Learning* (Springer, 2009).  
