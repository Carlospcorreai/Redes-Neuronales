<!DOCTYPE html>
<html lang="en"><head>
<script src="Clase Redes Neuronales_files/libs/clipboard/clipboard.min.js"></script>
<script src="Clase Redes Neuronales_files/libs/quarto-html/tabby.min.js"></script>
<script src="Clase Redes Neuronales_files/libs/quarto-html/popper.min.js"></script>
<script src="Clase Redes Neuronales_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Clase Redes Neuronales_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Clase Redes Neuronales_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Clase Redes Neuronales_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Clase Redes Neuronales_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Docente: Carlos Correa IÃ±iguez (c.correainiguez@uandresbello.edu)">
  <title>Redes Neuronales</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Clase Redes Neuronales_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Clase Redes Neuronales_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="Clase Redes Neuronales_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="unab.css">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Redes Neuronales</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Docente: Carlos Correa IÃ±iguez (<a href="mailto:c.correainiguez@uandresbello.edu" class="email">c.correainiguez@uandresbello.edu</a>) 
</div>
</div>
</div>

</section>
<section>
<section id="objetivos-de-la-clase" class="title-slide slide level1 center">
<h1>Objetivos de la Clase</h1>
<ul>
<li>Comprender la estructura bÃ¡sica de una red neuronal y cÃ³mo procesa informaciÃ³n a travÃ©s de las capas y funciones de activaciÃ³n.</li>
<li>Entender el proceso de entrenamiento de redes neuronales mediante aprendizaje supervisado y retropropagaciÃ³n.</li>
<li>Conocer aplicaciones actuales de las redes neuronales y familiarizarse con herramientas bÃ¡sicas para su implementaciÃ³n.</li>
</ul>
</section>
<section id="historia-de-las-redes-neuronales" class="slide level2">
<h2>Historia de las Redes Neuronales</h2>
<ul>
<li><p><strong>Origen y evoluciÃ³n</strong>: Desde los modelos iniciales en los aÃ±os 50 hasta las redes profundas actuales.</p></li>
<li><p><strong>Principales hitos</strong>:</p>
<ul>
<li><strong>1958</strong>: PerceptrÃ³n de Frank Rosenblatt.</li>
<li><strong>1986</strong>: PopularizaciÃ³n del algoritmo de retropropagaciÃ³n.</li>
<li><strong>2012</strong>: AlexNet gana ImageNet, marcando el auge del deep learning.</li>
</ul></li>
<li><p><strong>Aplicaciones modernas</strong>: VisiÃ³n por computadora, procesamiento del lenguaje natural, vehÃ­culos autÃ³nomos, entre otros.</p></li>
<li><p>En el siguiente video veremos un resumen de la historia de las redes neuronales:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=faiDJ1cCH7Q">Historia de las redes neuronales</a></li>
</ul></li>
</ul>
</section>
<section id="funcionamiento-del-sistema-visual-humano" class="slide level2">
<h2>Funcionamiento del Sistema Visual Humano</h2>
<ul>
<li>Compuesto por millones de neuronas interconectadas en Ã¡reas especializadas de la corteza visual (V1, V2, V3, V4 y V5).</li>
<li>Procesa imÃ¡genes de manera rÃ¡pida y eficaz, manejando gran cantidad de informaciÃ³n de forma inconsciente.</li>
<li>Inspira la arquitectura de redes neuronales convolucionales utilizadas en visiÃ³n por computadora.</li>
</ul>
</section>
<section id="reconocimiento-de-dÃ­gitos-escritos-a-mano" class="slide level2">
<h2>Reconocimiento de DÃ­gitos Escritos a Mano</h2>
<ul>
<li>Para los humanos, reconocer dÃ­gitos escritos a mano parece una tarea sencilla.</li>
<li>Sin embargo, replicar esta habilidad en un programa informÃ¡tico es un desafÃ­o considerable debido a la gran diversidad y variaciones en las formas de los dÃ­gitos, lo que genera numerosas excepciones.</li>
</ul>

<img data-src="Imagen1.png" class="r-stretch quarto-figure-center"><p class="caption">NÃºmeros escritos a mano</p></section>
<section id="redes-neuronales-y-reconocimiento-de-dÃ­gitos" class="slide level2">
<h2>Redes Neuronales y Reconocimiento de DÃ­gitos</h2>
<ul>
<li>Las redes neuronales abordan el problema del reconocimiento de dÃ­gitos de manera innovadora: aprenden a reconocer los dÃ­gitos escritos a mano a partir de ejemplos de entrenamiento, en lugar de seguir reglas explÃ­citas para cada forma.</li>
<li>A medida que se incrementa el nÃºmero de ejemplos de entrenamiento, el rendimiento de la red mejora, permitiendo reconocer patrones con mayor precisiÃ³n.</li>
</ul>
</section>
<section id="ejemplo-visual" class="slide level2">
<h2>Ejemplo Visual</h2>
<ul>
<li>Para los humanos, reconocer dÃ­gitos escritos a mano parece una tarea sencilla.</li>
<li>Sin embargo, replicar esta habilidad en un programa informÃ¡tico es un desafÃ­o considerable debido a la gran diversidad y variaciones en las formas de los dÃ­gitos, lo que genera numerosas excepciones.</li>
</ul>

<img data-src="Imagen2.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section id="quÃ©-es-una-red-neuronal" class="slide level2">
<h2>Â¿QuÃ© es una Red Neuronal?</h2>
<ul>
<li><strong>DefiniciÃ³n</strong>: Conjunto de neuronas artificiales interconectadas que simulan el funcionamiento de las neuronas biolÃ³gicas.</li>
<li><strong>Componentes clave</strong>:
<ul>
<li><strong>Neuronas (nodos)</strong>: Procesan la informaciÃ³n.</li>
<li><strong>Pesos</strong>: Determinan la importancia de cada seÃ±al de entrada.</li>
<li><strong>Funciones de activaciÃ³n</strong>: Deciden si una neurona debe activarse.</li>
</ul></li>
</ul>

<img data-src="Imagen3.png" style="width:60.0%" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section class="slide level2">


<img data-src="Imagen3.png" style="width:60.0%" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section id="el-perceptrÃ³n" class="slide level2">
<h2>El PerceptrÃ³n</h2>
<ul>
<li><strong>Desarrollado por</strong>: Frank Rosenblatt en los aÃ±os 50 y 60.</li>
<li><strong>Inspirado en</strong>: Trabajos de Warren McCulloch y Walter Pitts.</li>
<li><strong>CaracterÃ­sticas</strong>:
<ul>
<li>Toma entradas binarias y produce una salida binaria.</li>
<li>Es el modelo mÃ¡s simple de una red neuronal.</li>
</ul></li>
</ul>

<img data-src="Imagen4.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura del PerceptrÃ³n</p></section>
<section id="funcionamiento-de-un-perceptrÃ³n" class="slide level2">
<h2>Funcionamiento de un PerceptrÃ³n</h2>
<ol type="1">
<li>Toma varias entradas <span class="math inline">\((X_1, X_2, \dots)\)</span>.</li>
<li>Genera una Ãºnica salida binaria.</li>
</ol>
<p><span class="math display">\[
\sum_j w_j x_j &gt; \text{Umbral}
\]</span></p>
</section>
<section id="funciÃ³n-de-activaciÃ³n" class="slide level2">
<h2>FunciÃ³n de ActivaciÃ³n</h2>
<ul>
<li>La salida de la funciÃ³n de activaciÃ³n puede definirse de la siguiente manera: <span class="math display">\[
\text{output} =
\begin{cases}
0 &amp; \text{si } w \cdot x + b \leq 0 \\
1 &amp; \text{si } w \cdot x + b &gt; 0
\end{cases}
\]</span></li>
<li><strong>b</strong>: Sesgo, ajusta el umbral de activaciÃ³n del perceptrÃ³n.</li>
<li><strong>w</strong>: Pesos, determinan la importancia de cada entrada.</li>
<li><strong>x</strong>: Valores de entrada al perceptrÃ³n.</li>
</ul>
</section>
<section id="ejemplo-1-decisiÃ³n-de-asistir-a-un-festival" class="slide level2">
<h2>Ejemplo 1: DecisiÃ³n de asistir a un festival</h2>

<img data-src="Lollapalooza.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de funcionamiento de pesos</p></section>
<section id="ejemplo-2-implementaciÃ³n-de-puerta-nand-con-un-perceptrÃ³n" class="slide level2">
<h2>Ejemplo 2: ImplementaciÃ³n de Puerta NAND con un PerceptrÃ³n</h2>
<ul>
<li>Los perceptrones pueden calcular funciones lÃ³gicas elementales, como AND, OR, y NAND.</li>
<li>Supongamos que tenemos un perceptrÃ³n con dos entradas, cada una con un peso de -2, y un sesgo de 3:</li>
</ul>

<img data-src="Imagen6.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section class="slide level2">

<h3 id="resultado-implementaciÃ³n-de-puerta-nand-con-un-perceptrÃ³n">Resultado: ImplementaciÃ³n de Puerta NAND con un PerceptrÃ³n</h3>
<ul>
<li>Para la entrada (0 0) la salida es (1):</li>
</ul>
<p><span class="math display">\[
(-2) \cdot 0 + (-2) \cdot 0 + 3 = 3
\]</span></p>
<ul>
<li>Para la entrada (1 1), la salida es (0):</li>
</ul>
<p><span class="math display">\[
(-2) \cdot 1 + (-2) \cdot 1 + 3 = -1
\]</span></p>
</section>
<section id="neurona-sigmoide---problema-de-clasificaciÃ³n-errÃ³nea" class="slide level2">
<h2>Neurona Sigmoide - Problema de ClasificaciÃ³n ErrÃ³nea</h2>
<ul>
<li><p>Por ejemplo, supongamos que la red estaba clasificando errÃ³neamente una imagen como un â8â cuando deberÃ­a ser un â9â.</p></li>
<li><p>PodrÃ­amos averiguar cÃ³mo hacer un pequeÃ±o cambio en los pesos y sesgos para que la red se acerque un poco mÃ¡s a clasificar la imagen como un â9â.</p></li>
<li><p>Y luego repetirÃ­amos esto, cambiando los pesos y sesgos una y otra vez para producir una mejor producciÃ³n. La red estarÃ­a aprendiendo.</p></li>
</ul>

<img data-src="Imagen8.png" class="r-stretch quarto-figure-center"><p class="caption">Diagrama del Ejemplo</p></section>
<section id="neurona-sigmoide---cambios-en-los-pesos" class="slide level2">
<h2>Neurona Sigmoide - Cambios en los Pesos</h2>
<p>El problema es que esto no es lo que sucede cuando nuestra red contiene perceptrones.</p>
<ul>
<li><p>Un pequeÃ±o cambio en los pesos o sesgo de cualquier perceptrÃ³n individual en la red a veces puede hacer que la salida de ese perceptrÃ³n se voltee por completo.</p></li>
<li><p>Es decir, que la salida puede cambiar de 0 a 1, lo cual afecta significativamente el comportamiento de la red.</p></li>
</ul>
</section>
<section id="neurona-sigmoide--cambios-drÃ¡sticos-en-la-red" class="slide level2">
<h2>Neurona Sigmoide -Cambios DrÃ¡sticos en la Red</h2>
<p>Este giro puede hacer que el comportamiento del resto de la red cambie de manera muy complicada.</p>
<ul>
<li><p>Aunque ahora el â9â podrÃ­a clasificarse correctamente, el comportamiento de la red en otras imÃ¡genes puede cambiar completamente de manera difÃ­cil de controlar.</p></li>
<li><p>Esto complica la posibilidad de modificar gradualmente los pesos y sesgos para que la red se acerque al comportamiento deseado.</p></li>
</ul>
</section>
<section id="neurona-sigmoide---dificultad-para-aprender" class="slide level2">
<h2>Neurona Sigmoide - Dificultad para Aprender</h2>
<p>Tal vez haya alguna manera inteligente de solucionar este problema, pero no es inmediatamente obvio cÃ³mo hacer que una red de perceptrones aprenda.</p>
<ul>
<li>La dificultad radica en que los cambios en los pesos de una parte de la red pueden afectar de manera impredecible el comportamiento de la red en su totalidad.</li>
</ul>
</section>
<section id="neurona-sigmoide---introducciÃ³n-de-neuronas-sigmoides" class="slide level2">
<h2>Neurona Sigmoide - IntroducciÃ³n de Neuronas Sigmoides</h2>
<p>Podemos superar este problema introduciendo un nuevo tipo de neurona artificial llamada <strong>neurona sigmoide</strong>.</p>
<ul>
<li><p>Las neuronas sigmoides permiten un cambio gradual en la salida, en lugar de cambios abruptos como en los perceptrones.</p></li>
<li><p>Esto facilita el ajuste progresivo de los pesos y sesgos, permitiendo que la red âaprendaâ de manera mÃ¡s controlada y eficiente.</p></li>
<li><p>La clave para que una red neuronal aprenda gradualmente es utilizar neuronas sigmoides, que permiten ajustes suaves en lugar de cambios bruscos.</p></li>
<li><p>Este enfoque facilita el entrenamiento de la red, permitiendo mejorar la clasificaciÃ³n sin afectar negativamente el comportamiento en otras tareas.</p></li>
</ul>
</section>
<section id="neurona-sigmoide---funciÃ³n-de-activaciÃ³n-sigmoide" class="slide level2">
<h2>Neurona Sigmoide - FunciÃ³n de ActivaciÃ³n Sigmoide</h2>
<p>La <strong>funciÃ³n sigmoide</strong> es utilizada como funciÃ³n de activaciÃ³n en redes neuronales para permitir que las salidas varÃ­en suavemente entre 0 y 1:</p>
<p><span class="math display">\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]</span></p>
<div id="4cd5f044" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Clase%20Redes%20Neuronales_files/figure-revealjs/cell-2-output-1.png" width="515" height="377"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="perceptrÃ³n" class="slide level2">
<h2>PerceptrÃ³n</h2>
<p>El <strong>perceptrÃ³n</strong> es el modelo mÃ¡s simple de una red neuronal.</p>
<ul>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: FunciÃ³n escalÃ³n.</li>
<li><strong>Salida</strong>: Binaria (0 o 1).</li>
<li><strong>Usos principales</strong>: ClasificaciÃ³n binaria.</li>
<li><strong>Limitaciones</strong>: No puede resolver problemas no lineales (ej. XOR).</li>
</ul>
<p><strong>Arquitectura de un PerceptrÃ³n</strong>:</p>

<img data-src="perceptron_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura PerceptrÃ³n</p></section>
<section id="neurona-sigmoide" class="slide level2">
<h2>Neurona Sigmoide</h2>
<p>Las <strong>neuronas sigmoides</strong> permiten obtener salidas continuas.</p>
<ul>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: <span class="math inline">\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</span></li>
<li><strong>Salida</strong>: Continua entre 0 y 1.</li>
<li><strong>Usos principales</strong>: Problemas de clasificaciÃ³n probabilÃ­stica.</li>
</ul>
<p><strong>Arquitectura de una Neurona Sigmoide</strong>:</p>

<img data-src="sigmoid_neuron_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura Neurona Sigmoide</p></section>
<section id="relu-rectificador-lineal-unitario" class="slide level2">
<h2>ReLU (Rectificador Lineal Unitario)</h2>
<p>La funciÃ³n <strong>ReLU</strong> es la mÃ¡s utilizada en redes neuronales profundas.</p>
<ul>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: <span class="math inline">\(ReLU(z) = max(0, z)\)</span></li>
<li><strong>Salida</strong>: Continua entre 0 y <span class="math inline">\(\infty\)</span>.</li>
<li><strong>Usos principales</strong>: Redes profundas y convolucionales.</li>
</ul>
<p><strong>Arquitectura de una Red con ReLU</strong>:</p>

<img data-src="relu_network_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura ReLU</p></section>
<section id="tangente-hiperbÃ³lica-tanh" class="slide level2">
<h2>Tangente HiperbÃ³lica (tanh)</h2>
<p>La funciÃ³n <strong>tanh</strong> es similar a la sigmoide pero ofrece salidas entre -1 y 1.</p>
<ul>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: <span class="math inline">\(tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\)</span></li>
<li><strong>Salida</strong>: Continua entre -1 y 1.</li>
<li><strong>Usos principales</strong>: Redes recurrentes y algunas redes convolucionales.</li>
</ul>
<p><strong>Arquitectura de una Red con tanh</strong>:</p>

<img data-src="tanh_network_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura tanh</p></section>
<section id="redes-neuronales-convolucionales-cnns" class="slide level2">
<h2>Redes Neuronales Convolucionales (CNNs)</h2>
<p>Las <strong>redes neuronales convolucionales (CNNs)</strong> son ampliamente utilizadas para problemas de visiÃ³n por computadora.</p>
<ul>
<li><strong>Arquitectura</strong>: Compuesta por capas de convoluciÃ³n, pooling y fully connected.</li>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: ReLU es la mÃ¡s comÃºn.</li>
<li><strong>Usos principales</strong>: ClasificaciÃ³n de imÃ¡genes, detecciÃ³n de objetos.</li>
</ul>
<p><strong>Arquitectura de una CNN</strong>:</p>

<img data-src="cnn_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura CNN</p></section>
<section id="redes-neuronales-recurrentes-rnns" class="slide level2">
<h2>Redes Neuronales Recurrentes (RNNs)</h2>
<p>Las <strong>redes neuronales recurrentes (RNNs)</strong> son efectivas para problemas secuenciales.</p>
<ul>
<li><strong>Arquitectura</strong>: Los nodos tienen conexiones hacia adelante y hacia atrÃ¡s, lo que permite tener âmemoriaâ.</li>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: <strong>tanh</strong> y <strong>sigmoide</strong>.</li>
<li><strong>Usos principales</strong>: Procesamiento de lenguaje natural, series temporales.</li>
</ul>
<p><strong>Arquitectura de una RNN</strong>:</p>

<img data-src="rnn_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura RNN</p></section>
<section id="redes-de-memoria-a-largo-plazo-lstm" class="slide level2">
<h2>Redes de Memoria a Largo Plazo (LSTM)</h2>
<p>Las <strong>LSTM (Long Short-Term Memory)</strong> son un tipo especial de RNN que pueden aprender dependencias a largo plazo.</p>
<ul>
<li><strong>Arquitectura</strong>: Incluyen âceldas de memoriaâ que permiten almacenar informaciÃ³n durante largos periodos.</li>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: <strong>tanh</strong> y <strong>sigmoide</strong>.</li>
<li><strong>Usos principales</strong>: AnÃ¡lisis de secuencias largas.</li>
</ul>
<p><strong>Arquitectura de una LSTM</strong>:</p>

<img data-src="lstm_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura LSTM</p></section>
<section id="redes-de-retroalimentaciÃ³n-feedback-networks" class="slide level2">
<h2>Redes de RetroalimentaciÃ³n (Feedback Networks)</h2>
<p>Estas redes permiten que las salidas de ciertas capas alimenten a las capas anteriores.</p>
<ul>
<li><strong>FunciÃ³n de activaciÃ³n</strong>: <strong>sigmoide</strong>, <strong>tanh</strong>, y a veces <strong>ReLU</strong>.</li>
<li><strong>Usos principales</strong>: AnÃ¡lisis de datos donde las salidas deben influir en las entradas anteriores.</li>
</ul>
<p><strong>Arquitectura de una Red de RetroalimentaciÃ³n</strong>:</p>

<img data-src="feedback_network_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura Feedback</p></section>
<section id="comparaciÃ³n-de-redes-neuronales-y-funciones-de-activaciÃ³n" class="slide level2">
<h2>ComparaciÃ³n de Redes Neuronales y Funciones de ActivaciÃ³n</h2>
<table class="caption-top">
<colgroup>
<col style="width: 23%">
<col style="width: 14%">
<col style="width: 23%">
<col style="width: 24%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Red Neuronal / FunciÃ³n de ActivaciÃ³n</strong></th>
<th><strong>Salida</strong></th>
<th><strong>FunciÃ³n de ActivaciÃ³n</strong></th>
<th><strong>Usos Principales</strong></th>
<th><strong>Entrada</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>PerceptrÃ³n</strong></td>
<td>Binaria (0 o 1)</td>
<td>FunciÃ³n escalÃ³n</td>
<td>ClasificaciÃ³n binaria</td>
<td>Binaria</td>
</tr>
<tr class="even">
<td><strong>Sigmoide</strong></td>
<td>Continua (0 a 1)</td>
<td><span class="math inline">\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</span></td>
<td>ClasificaciÃ³n probabilÃ­stica</td>
<td>NumÃ©rica continua</td>
</tr>
<tr class="odd">
<td><strong>ReLU (Rectificador Lineal Unitario)</strong></td>
<td><span class="math inline">\(max(0, z)\)</span></td>
<td><span class="math inline">\(ReLU(z) = max(0, z)\)</span></td>
<td>Redes profundas y convolucionales</td>
<td>NumÃ©rica continua</td>
</tr>
<tr class="even">
<td><strong>tanh (Tangente HiperbÃ³lica)</strong></td>
<td>Continua (-1 a 1)</td>
<td><span class="math inline">\(tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\)</span></td>
<td>Redes recurrentes y algunas convolucionales</td>
<td>NumÃ©rica continua</td>
</tr>
</tbody>
</table>
<aside class="notes">
Esta tabla muestra las diferencias entre los tipos de redes neuronales y las funciones de activaciÃ³n que utilizan.
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="introducciÃ³n-al-backpropagation" class="slide level2">
<h2>IntroducciÃ³n al Backpropagation</h2>
<p>El algoritmo de <strong>backpropagation</strong> se utiliza para ajustar los pesos de una red neuronal minimizando el error entre la salida esperada y la salida obtenida.</p>
<h3 id="por-quÃ©-es-importante-backpropagation">Â¿Por quÃ© es Importante Backpropagation?</h3>
<ul>
<li>Permite a las redes neuronales aprender de los datos y mejorar sus predicciones.</li>
<li>Optimiza los pesos para minimizar el error a travÃ©s de un proceso iterativo.</li>
</ul>
</section>
<section id="ciclo-completo-de-backpropagation" class="slide level2">
<h2>Ciclo Completo de Backpropagation</h2>
<ol type="1">
<li><strong>Forward Propagation</strong>: Se calcula la salida.</li>
<li><strong>CÃ¡lculo del Error</strong>: Se mide el error entre la salida predicha y la real.</li>
<li><strong>Backward Propagation</strong>: Se ajustan los pesos propagando el error hacia atrÃ¡s.</li>
<li><strong>ActualizaciÃ³n de Pesos</strong>: Los pesos se ajustan utilizando el gradiente de la funciÃ³n de pÃ©rdida.</li>
</ol>
</section>
<section id="ajuste-de-pesos-en-una-red-neuronal" class="slide level2">
<h2>Ajuste de Pesos en una Red Neuronal</h2>
<ul>
<li>Cada neurona realiza una suma ponderada de sus entradas: <span class="math display">\[
z = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b
\]</span></li>
<li>La salida de la neurona se obtiene aplicando una funciÃ³n de activaciÃ³n: <span class="math display">\[
y = f(z)
\]</span></li>
</ul>
</section>
<section id="funciÃ³n-de-pÃ©rdida-y-el-gradiente" class="slide level2">
<h2>FunciÃ³n de PÃ©rdida y el Gradiente</h2>
<ul>
<li>La funciÃ³n de pÃ©rdida mide quÃ© tan lejos estÃ¡ la predicciÃ³n de la salida correcta: <span class="math display">\[
L = \frac{1}{2} (y_{\text{pred}} - y_{\text{real}})^2
\]</span></li>
<li>Los pesos se ajustan utilizando el descenso de gradiente: <span class="math display">\[
w_i(t+1) = w_i(t) - \eta \frac{\partial L}{\partial w_i}
\]</span></li>
</ul>
</section>
<section id="ecuaciÃ³n-diferencial-en-backpropagation" class="slide level2">
<h2>EcuaciÃ³n Diferencial en Backpropagation</h2>
<ul>
<li>El ajuste de los pesos sigue una ecuaciÃ³n diferencial: <span class="math display">\[
\frac{d w_i}{d t} = - \frac{\partial L}{\partial w_i}
\]</span></li>
</ul>
</section></section>
<section>
<section id="ejemplo" class="title-slide slide level1 center">
<h1>Ejemplo</h1>
<ul>
<li><p>Entrada: <span class="math inline">\(x_1 = 0.5\)</span>, <span class="math inline">\(x_2 = 0.1\)</span></p></li>
<li><p>Salida esperada: <span class="math inline">\(y_{\text{esperado}} = 1\)</span></p></li>
<li><p>Pesos iniciales:</p>
<ul>
<li><span class="math inline">\(w_{11}^{(1)} = 0.4\)</span>, <span class="math inline">\(w_{12}^{(1)} = 0.2\)</span></li>
<li><span class="math inline">\(w_{21}^{(1)} = 0.1\)</span>, <span class="math inline">\(w_{22}^{(1)} = 0.3\)</span></li>
<li><span class="math inline">\(w_1^{(2)} = 0.6\)</span>, <span class="math inline">\(w_2^{(2)} = 0.5\)</span></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li>Tasa de aprendizaje: <span class="math inline">\(\eta = 0.1\)</span></li>
</ul>
</section>
<section id="paso-1-forward-propagation" class="slide level2">
<h2>Paso 1: Forward Propagation</h2>
<p><strong>CÃ¡lculo de las entradas a las neuronas ocultas</strong>:</p>
<p>Para la neurona oculta 1:</p>
<p><span class="math display">\[
z_1 = w_{11}^{(1)} \cdot x_1 + w_{12}^{(1)} \cdot x_2 = (0.4 \cdot 0.5) + (0.2 \cdot 0.1) = 0.22
\]</span></p>
<p>Para la neurona oculta 2:</p>
<p><span class="math display">\[
z_2 = w_{21}^{(1)} \cdot x_1 + w_{22}^{(1)} \cdot x_2 = (0.1 \cdot 0.5) + (0.3 \cdot 0.1) = 0.08
\]</span></p>
</section>
<section id="funciÃ³n-de-activaciÃ³n-sigmoide" class="slide level2">
<h2>FunciÃ³n de ActivaciÃ³n Sigmoide</h2>
<p>Aplicando la funciÃ³n de activaciÃ³n sigmoide a las neuronas ocultas:</p>
<p>Para la neurona oculta 1:</p>
<p><span class="math display">\[
a_1 = \frac{1}{1 + e^{-z_1}} = \frac{1}{1 + e^{-0.22}} \approx 0.554
\]</span></p>
<p>Para la neurona oculta 2:</p>
<p><span class="math display">\[
a_2 = \frac{1}{1 + e^{-z_2}} = \frac{1}{1 + e^{-0.08}} \approx 0.520
\]</span></p>
</section>
<section id="entrada-a-la-neurona-de-salida" class="slide level2">
<h2>Entrada a la Neurona de Salida</h2>
<p><span class="math display">\[
z_{\text{salida}} = w_1^{(2)} \cdot a_1 + w_2^{(2)} \cdot a_2 = (0.6 \cdot 0.554) + (0.5 \cdot 0.520) \approx 0.612
\]</span></p>
<p>Aplicando la funciÃ³n de activaciÃ³n sigmoide a la neurona de salida:</p>
<p><span class="math display">\[
a_{\text{salida}} = \frac{1}{1 + e^{-z_{\text{salida}}}} = \frac{1}{1 + e^{-0.612}} \approx 0.648
\]</span></p>
</section>
<section id="paso-2-cÃ¡lculo-del-error" class="slide level2">
<h2>Paso 2: CÃ¡lculo del Error</h2>
<p>El error en la salida es:</p>
<p><span class="math display">\[
\text{Error} = y_{\text{esperado}} - a_{\text{salida}} = 1 - 0.648 = 0.352
\]</span></p>
</section>
<section id="paso-3-backpropagation" class="slide level2">
<h2>Paso 3: Backpropagation</h2>
<h3 id="cÃ¡lculo-del-gradiente-de-la-neurona-de-salida">CÃ¡lculo del gradiente de la neurona de salida:</h3>
<p>La derivada de la funciÃ³n sigmoide es:</p>
<p><span class="math display">\[
\delta_{\text{salida}} = a_{\text{salida}} \cdot (1 - a_{\text{salida}}) \cdot \text{Error} = 0.648 \cdot (1 - 0.648) \cdot 0.352 \approx 0.080
\]</span></p>
</section>
<section id="actualizaciÃ³n-de-los-pesos-salida-a-ocultas" class="slide level2">
<h2>ActualizaciÃ³n de los Pesos (Salida a Ocultas)</h2>
<p>Actualizar los pesos entre las neuronas ocultas y la neurona de salida:</p>
<p>Para <span class="math inline">\(w_1^{(2)}\)</span>:</p>
<p><span class="math display">\[
w_1^{(2)} = w_1^{(2)} + \eta \cdot \delta_{\text{salida}} \cdot a_1 = 0.6 + 0.1 \cdot 0.080 \cdot 0.554 \approx 0.604
\]</span></p>
<p>Para <span class="math inline">\(w_2^{(2)}\)</span>:</p>
<p><span class="math display">\[
w_2^{(2)} = w_2^{(2)} + \eta \cdot \delta_{\text{salida}} \cdot a_2 = 0.5 + 0.1 \cdot 0.080 \cdot 0.520 \approx 0.504
\]</span></p>
</section>
<section id="actualizaciÃ³n-de-los-pesos-entradas-a-ocultas" class="slide level2">
<h2>ActualizaciÃ³n de los Pesos (Entradas a Ocultas)</h2>
<p>Gradientes de las neuronas ocultas:</p>
<p>Para la neurona oculta 1:</p>
<p><span class="math display">\[
\delta_1 = a_1 \cdot (1 - a_1) \cdot \delta_{\text{salida}} \cdot w_1^{(2)} = 0.554 \cdot (1 - 0.554) \cdot 0.080 \cdot 0.6 \approx 0.011
\]</span></p>
<p>Para la neurona oculta 2:</p>
<p><span class="math display">\[
\delta_2 = a_2 \cdot (1 - a_2) \cdot \delta_{\text{salida}} \cdot w_2^{(2)} = 0.520 \cdot (1 - 0.520) \cdot 0.080 \cdot 0.5 \approx 0.010
\]</span></p>
</section>
<section id="ajuste-final-de-pesos" class="slide level2">
<h2>Ajuste Final de Pesos</h2>
<p>Actualizar los pesos entre las entradas y las neuronas ocultas:</p>
<p>Para <span class="math inline">\(w_{11}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{11}^{(1)} = w_{11}^{(1)} + \eta \cdot \delta_1 \cdot x_1 = 0.4 + 0.1 \cdot 0.011 \cdot 0.5 \approx 0.401
\]</span></p>
<p>Para <span class="math inline">\(w_{12}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{12}^{(1)} = w_{12}^{(1)} + \eta \cdot \delta_1 \cdot x_2 = 0.2 + 0.1 \cdot 0.011 \cdot 0.1 \approx 0.2001
\]</span></p>
<p>Para <span class="math inline">\(w_{21}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{21}^{(1)} = w_{21}^{(1)} + \eta \cdot \delta_2 \cdot x_1 = 0.1 + 0.1 \cdot 0.010 \cdot 0.5 \approx 0.101
\]</span></p>
<p>Para <span class="math inline">\(w_{22}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{22}^{(1)} = w_{22}^{(1)} + \eta \cdot \delta_2 \cdot x_2 = 0.3 + 0.1 \cdot 0.010 \cdot 0.1 \approx 0.3001
\]</span></p>
</section>
<section id="resultados" class="slide level2">
<h2>Resultados</h2>
<ul>
<li>Los pesos han sido ajustados despuÃ©s de aplicar el algoritmo de <strong>backpropagation</strong>.</li>
<li>El proceso se repite hasta que el error se minimiza a un nivel aceptable.</li>
</ul>
</section>
<section id="aplicaciones-actuales-de-las-redes-neuronales" class="slide level2">
<h2>Aplicaciones Actuales de las Redes Neuronales</h2>
<h3 id="visiÃ³n-por-computadora">VisiÃ³n por Computadora</h3>
<ul>
<li><strong>Reconocimiento de imÃ¡genes y objetos</strong>: ClasificaciÃ³n y detecciÃ³n en tiempo real.</li>
<li><strong>ConducciÃ³n autÃ³noma</strong>: InterpretaciÃ³n del entorno por vehÃ­culos sin conductor.</li>
<li><strong>DiagnÃ³stico mÃ©dico</strong>: DetecciÃ³n de anomalÃ­as en imÃ¡genes mÃ©dicas.</li>
</ul>
</section>
<section id="procesamiento-del-lenguaje-natural-nlp" class="slide level2">
<h2>Procesamiento del Lenguaje Natural (NLP)</h2>
<ul>
<li><strong>TraducciÃ³n automÃ¡tica</strong>: ConversiÃ³n entre idiomas en tiempo real.</li>
<li><strong>AnÃ¡lisis de sentimiento</strong>: InterpretaciÃ³n de opiniones en redes sociales.</li>
<li><strong>Chatbots y asistentes virtuales</strong>: InteracciÃ³n humana con sistemas inteligentes.</li>
</ul>
</section>
<section id="generaciÃ³n-de-contenido" class="slide level2">
<h2>GeneraciÃ³n de Contenido</h2>
<ul>
<li><strong>Redes Generativas Adversariales (GANs)</strong>:
<ul>
<li>CreaciÃ³n de imÃ¡genes, mÃºsica y texto artificiales.</li>
</ul></li>
<li><strong>Deepfakes</strong>: SÃ­ntesis de videos y audios realistas pero falsos.</li>
</ul>
</section>
<section id="otros-campos-de-aplicaciÃ³n" class="slide level2">
<h2>Otros Campos de AplicaciÃ³n</h2>
<ul>
<li><strong>Finanzas</strong>: PredicciÃ³n de mercados y detecciÃ³n de fraudes.</li>
<li><strong>Agricultura</strong>: Monitoreo de cultivos y optimizaciÃ³n de recursos.</li>
<li><strong>Ciencias Ambientales</strong>: Modelado climÃ¡tico y predicciÃ³n de desastres naturales.</li>
</ul>
</section>
<section id="conclusiones" class="slide level2">
<h2>Conclusiones</h2>
<ul>
<li><strong>EvoluciÃ³n constante</strong>: Las redes neuronales siguen avanzando, impulsadas por nuevos algoritmos y mayor poder computacional.</li>
<li><strong>Amplia aplicabilidad</strong>: Su capacidad para abordar problemas complejos las hace indispensables en mÃºltiples industrias.</li>
<li><strong>DesafÃ­os futuros</strong>:
<ul>
<li>Interpretabilidad de modelos.</li>
<li>Eficiencia energÃ©tica y computacional.</li>
<li>Ãtica y sesgos en inteligencia artificial.</li>
</ul></li>
</ul>
</section>
<section id="conclusiÃ³n-de-la-clase" class="slide level2">
<h2>ConclusiÃ³n de la Clase</h2>
<p>En conclusiÃ³n, hemos explorado los conceptos fundamentales de las redes neuronales, desde su origen hasta sus aplicaciones actuales en diversos campos. El aprendizaje profundo ha transformado la manera en que abordamos problemas complejos, y su evoluciÃ³n continÃºa abriendo nuevas oportunidades y desafÃ­os. Es esencial mantenernos actualizados y considerar las implicaciones Ã©ticas y sociales al desarrollar y aplicar estas tecnologÃ­as.</p>
</section>
<section id="referencias" class="slide level2">
<h2>Referencias</h2>
<ol type="1">
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A.</strong> (2016). <em>Deep Learning</em>. MIT Press.</li>
<li><strong>Nielsen, M. A.</strong> (2015). <em>Neural Networks and Deep Learning</em>. Disponible en <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a>.</li>
<li><strong>Chollet, F.</strong> (2018). <em>Deep Learning with Python</em>. Manning Publications.</li>
</ol>
</section>
<section class="slide level2">

<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>