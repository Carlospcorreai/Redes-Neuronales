<!DOCTYPE html>
<html lang="en"><head>
<script src="Clase Redes Neuronales_files/libs/clipboard/clipboard.min.js"></script>
<script src="Clase Redes Neuronales_files/libs/quarto-html/tabby.min.js"></script>
<script src="Clase Redes Neuronales_files/libs/quarto-html/popper.min.js"></script>
<script src="Clase Redes Neuronales_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Clase Redes Neuronales_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Clase Redes Neuronales_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Clase Redes Neuronales_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Clase Redes Neuronales_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Docente: Carlos Correa Iñiguez (c.correainiguez@uandresbello.edu)">
  <title>Redes Neuronales</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Clase Redes Neuronales_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Clase Redes Neuronales_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="Clase Redes Neuronales_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="unab.css">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Redes Neuronales</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Docente: Carlos Correa Iñiguez (<a href="mailto:c.correainiguez@uandresbello.edu" class="email">c.correainiguez@uandresbello.edu</a>) 
</div>
</div>
</div>

</section>
<section>
<section id="objetivos-de-la-clase" class="title-slide slide level1 center">
<h1>Objetivos de la Clase</h1>
<ul>
<li>Comprender la estructura básica de una red neuronal y cómo procesa información a través de las capas y funciones de activación.</li>
<li>Entender el proceso de entrenamiento de redes neuronales mediante aprendizaje supervisado y retropropagación.</li>
<li>Conocer aplicaciones actuales de las redes neuronales y familiarizarse con herramientas básicas para su implementación.</li>
</ul>
</section>
<section id="historia-de-las-redes-neuronales" class="slide level2">
<h2>Historia de las Redes Neuronales</h2>
<ul>
<li><p><strong>Origen y evolución</strong>: Desde los modelos iniciales en los años 50 hasta las redes profundas actuales.</p></li>
<li><p><strong>Principales hitos</strong>:</p>
<ul>
<li><strong>1958</strong>: Perceptrón de Frank Rosenblatt.</li>
<li><strong>1986</strong>: Popularización del algoritmo de retropropagación.</li>
<li><strong>2012</strong>: AlexNet gana ImageNet, marcando el auge del deep learning.</li>
</ul></li>
<li><p><strong>Aplicaciones modernas</strong>: Visión por computadora, procesamiento del lenguaje natural, vehículos autónomos, entre otros.</p></li>
<li><p>En el siguiente video veremos un resumen de la historia de las redes neuronales:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=faiDJ1cCH7Q">Historia de las redes neuronales</a></li>
</ul></li>
</ul>
</section>
<section id="funcionamiento-del-sistema-visual-humano" class="slide level2">
<h2>Funcionamiento del Sistema Visual Humano</h2>
<ul>
<li>Compuesto por millones de neuronas interconectadas en áreas especializadas de la corteza visual (V1, V2, V3, V4 y V5).</li>
<li>Procesa imágenes de manera rápida y eficaz, manejando gran cantidad de información de forma inconsciente.</li>
<li>Inspira la arquitectura de redes neuronales convolucionales utilizadas en visión por computadora.</li>
</ul>
</section>
<section id="reconocimiento-de-dígitos-escritos-a-mano" class="slide level2">
<h2>Reconocimiento de Dígitos Escritos a Mano</h2>
<ul>
<li>Para los humanos, reconocer dígitos escritos a mano parece una tarea sencilla.</li>
<li>Sin embargo, replicar esta habilidad en un programa informático es un desafío considerable debido a la gran diversidad y variaciones en las formas de los dígitos, lo que genera numerosas excepciones.</li>
</ul>

<img data-src="Imagen1.png" class="r-stretch quarto-figure-center"><p class="caption">Números escritos a mano</p></section>
<section id="redes-neuronales-y-reconocimiento-de-dígitos" class="slide level2">
<h2>Redes Neuronales y Reconocimiento de Dígitos</h2>
<ul>
<li>Las redes neuronales abordan el problema del reconocimiento de dígitos de manera innovadora: aprenden a reconocer los dígitos escritos a mano a partir de ejemplos de entrenamiento, en lugar de seguir reglas explícitas para cada forma.</li>
<li>A medida que se incrementa el número de ejemplos de entrenamiento, el rendimiento de la red mejora, permitiendo reconocer patrones con mayor precisión.</li>
</ul>
</section>
<section id="ejemplo-visual" class="slide level2">
<h2>Ejemplo Visual</h2>
<ul>
<li>Para los humanos, reconocer dígitos escritos a mano parece una tarea sencilla.</li>
<li>Sin embargo, replicar esta habilidad en un programa informático es un desafío considerable debido a la gran diversidad y variaciones en las formas de los dígitos, lo que genera numerosas excepciones.</li>
</ul>

<img data-src="Imagen2.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section id="qué-es-una-red-neuronal" class="slide level2">
<h2>¿Qué es una Red Neuronal?</h2>
<ul>
<li><strong>Definición</strong>: Conjunto de neuronas artificiales interconectadas que simulan el funcionamiento de las neuronas biológicas.</li>
<li><strong>Componentes clave</strong>:
<ul>
<li><strong>Neuronas (nodos)</strong>: Procesan la información.</li>
<li><strong>Pesos</strong>: Determinan la importancia de cada señal de entrada.</li>
<li><strong>Funciones de activación</strong>: Deciden si una neurona debe activarse.</li>
</ul></li>
</ul>

<img data-src="Imagen3.png" style="width:60.0%" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section class="slide level2">


<img data-src="Imagen3.png" style="width:60.0%" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section id="el-perceptrón" class="slide level2">
<h2>El Perceptrón</h2>
<ul>
<li><strong>Desarrollado por</strong>: Frank Rosenblatt en los años 50 y 60.</li>
<li><strong>Inspirado en</strong>: Trabajos de Warren McCulloch y Walter Pitts.</li>
<li><strong>Características</strong>:
<ul>
<li>Toma entradas binarias y produce una salida binaria.</li>
<li>Es el modelo más simple de una red neuronal.</li>
</ul></li>
</ul>

<img data-src="Imagen4.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura del Perceptrón</p></section>
<section id="funcionamiento-de-un-perceptrón" class="slide level2">
<h2>Funcionamiento de un Perceptrón</h2>
<ol type="1">
<li>Toma varias entradas <span class="math inline">\((X_1, X_2, \dots)\)</span>.</li>
<li>Genera una única salida binaria.</li>
</ol>
<p><span class="math display">\[
\sum_j w_j x_j &gt; \text{Umbral}
\]</span></p>
</section>
<section id="función-de-activación" class="slide level2">
<h2>Función de Activación</h2>
<ul>
<li>La salida de la función de activación puede definirse de la siguiente manera: <span class="math display">\[
\text{output} =
\begin{cases}
0 &amp; \text{si } w \cdot x + b \leq 0 \\
1 &amp; \text{si } w \cdot x + b &gt; 0
\end{cases}
\]</span></li>
<li><strong>b</strong>: Sesgo, ajusta el umbral de activación del perceptrón.</li>
<li><strong>w</strong>: Pesos, determinan la importancia de cada entrada.</li>
<li><strong>x</strong>: Valores de entrada al perceptrón.</li>
</ul>
</section>
<section id="ejemplo-1-decisión-de-asistir-a-un-festival" class="slide level2">
<h2>Ejemplo 1: Decisión de asistir a un festival</h2>

<img data-src="Lollapalooza.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de funcionamiento de pesos</p></section>
<section id="ejemplo-2-implementación-de-puerta-nand-con-un-perceptrón" class="slide level2">
<h2>Ejemplo 2: Implementación de Puerta NAND con un Perceptrón</h2>
<ul>
<li>Los perceptrones pueden calcular funciones lógicas elementales, como AND, OR, y NAND.</li>
<li>Supongamos que tenemos un perceptrón con dos entradas, cada una con un peso de -2, y un sesgo de 3:</li>
</ul>

<img data-src="Imagen6.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplo de Red Neuronal</p></section>
<section class="slide level2">

<h3 id="resultado-implementación-de-puerta-nand-con-un-perceptrón">Resultado: Implementación de Puerta NAND con un Perceptrón</h3>
<ul>
<li>Para la entrada (0 0) la salida es (1):</li>
</ul>
<p><span class="math display">\[
(-2) \cdot 0 + (-2) \cdot 0 + 3 = 3
\]</span></p>
<ul>
<li>Para la entrada (1 1), la salida es (0):</li>
</ul>
<p><span class="math display">\[
(-2) \cdot 1 + (-2) \cdot 1 + 3 = -1
\]</span></p>
</section>
<section id="neurona-sigmoide---problema-de-clasificación-errónea" class="slide level2">
<h2>Neurona Sigmoide - Problema de Clasificación Errónea</h2>
<ul>
<li><p>Por ejemplo, supongamos que la red estaba clasificando erróneamente una imagen como un “8” cuando debería ser un “9”.</p></li>
<li><p>Podríamos averiguar cómo hacer un pequeño cambio en los pesos y sesgos para que la red se acerque un poco más a clasificar la imagen como un “9”.</p></li>
<li><p>Y luego repetiríamos esto, cambiando los pesos y sesgos una y otra vez para producir una mejor producción. La red estaría aprendiendo.</p></li>
</ul>

<img data-src="Imagen8.png" class="r-stretch quarto-figure-center"><p class="caption">Diagrama del Ejemplo</p></section>
<section id="neurona-sigmoide---cambios-en-los-pesos" class="slide level2">
<h2>Neurona Sigmoide - Cambios en los Pesos</h2>
<p>El problema es que esto no es lo que sucede cuando nuestra red contiene perceptrones.</p>
<ul>
<li><p>Un pequeño cambio en los pesos o sesgo de cualquier perceptrón individual en la red a veces puede hacer que la salida de ese perceptrón se voltee por completo.</p></li>
<li><p>Es decir, que la salida puede cambiar de 0 a 1, lo cual afecta significativamente el comportamiento de la red.</p></li>
</ul>
</section>
<section id="neurona-sigmoide--cambios-drásticos-en-la-red" class="slide level2">
<h2>Neurona Sigmoide -Cambios Drásticos en la Red</h2>
<p>Este giro puede hacer que el comportamiento del resto de la red cambie de manera muy complicada.</p>
<ul>
<li><p>Aunque ahora el “9” podría clasificarse correctamente, el comportamiento de la red en otras imágenes puede cambiar completamente de manera difícil de controlar.</p></li>
<li><p>Esto complica la posibilidad de modificar gradualmente los pesos y sesgos para que la red se acerque al comportamiento deseado.</p></li>
</ul>
</section>
<section id="neurona-sigmoide---dificultad-para-aprender" class="slide level2">
<h2>Neurona Sigmoide - Dificultad para Aprender</h2>
<p>Tal vez haya alguna manera inteligente de solucionar este problema, pero no es inmediatamente obvio cómo hacer que una red de perceptrones aprenda.</p>
<ul>
<li>La dificultad radica en que los cambios en los pesos de una parte de la red pueden afectar de manera impredecible el comportamiento de la red en su totalidad.</li>
</ul>
</section>
<section id="neurona-sigmoide---introducción-de-neuronas-sigmoides" class="slide level2">
<h2>Neurona Sigmoide - Introducción de Neuronas Sigmoides</h2>
<p>Podemos superar este problema introduciendo un nuevo tipo de neurona artificial llamada <strong>neurona sigmoide</strong>.</p>
<ul>
<li><p>Las neuronas sigmoides permiten un cambio gradual en la salida, en lugar de cambios abruptos como en los perceptrones.</p></li>
<li><p>Esto facilita el ajuste progresivo de los pesos y sesgos, permitiendo que la red “aprenda” de manera más controlada y eficiente.</p></li>
<li><p>La clave para que una red neuronal aprenda gradualmente es utilizar neuronas sigmoides, que permiten ajustes suaves en lugar de cambios bruscos.</p></li>
<li><p>Este enfoque facilita el entrenamiento de la red, permitiendo mejorar la clasificación sin afectar negativamente el comportamiento en otras tareas.</p></li>
</ul>
</section>
<section id="neurona-sigmoide---función-de-activación-sigmoide" class="slide level2">
<h2>Neurona Sigmoide - Función de Activación Sigmoide</h2>
<p>La <strong>función sigmoide</strong> es utilizada como función de activación en redes neuronales para permitir que las salidas varíen suavemente entre 0 y 1:</p>
<p><span class="math display">\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]</span></p>
<div id="4cd5f044" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Clase%20Redes%20Neuronales_files/figure-revealjs/cell-2-output-1.png" width="515" height="377"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="perceptrón" class="slide level2">
<h2>Perceptrón</h2>
<p>El <strong>perceptrón</strong> es el modelo más simple de una red neuronal.</p>
<ul>
<li><strong>Función de activación</strong>: Función escalón.</li>
<li><strong>Salida</strong>: Binaria (0 o 1).</li>
<li><strong>Usos principales</strong>: Clasificación binaria.</li>
<li><strong>Limitaciones</strong>: No puede resolver problemas no lineales (ej. XOR).</li>
</ul>
<p><strong>Arquitectura de un Perceptrón</strong>:</p>

<img data-src="perceptron_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura Perceptrón</p></section>
<section id="neurona-sigmoide" class="slide level2">
<h2>Neurona Sigmoide</h2>
<p>Las <strong>neuronas sigmoides</strong> permiten obtener salidas continuas.</p>
<ul>
<li><strong>Función de activación</strong>: <span class="math inline">\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</span></li>
<li><strong>Salida</strong>: Continua entre 0 y 1.</li>
<li><strong>Usos principales</strong>: Problemas de clasificación probabilística.</li>
</ul>
<p><strong>Arquitectura de una Neurona Sigmoide</strong>:</p>

<img data-src="sigmoid_neuron_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura Neurona Sigmoide</p></section>
<section id="relu-rectificador-lineal-unitario" class="slide level2">
<h2>ReLU (Rectificador Lineal Unitario)</h2>
<p>La función <strong>ReLU</strong> es la más utilizada en redes neuronales profundas.</p>
<ul>
<li><strong>Función de activación</strong>: <span class="math inline">\(ReLU(z) = max(0, z)\)</span></li>
<li><strong>Salida</strong>: Continua entre 0 y <span class="math inline">\(\infty\)</span>.</li>
<li><strong>Usos principales</strong>: Redes profundas y convolucionales.</li>
</ul>
<p><strong>Arquitectura de una Red con ReLU</strong>:</p>

<img data-src="relu_network_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura ReLU</p></section>
<section id="tangente-hiperbólica-tanh" class="slide level2">
<h2>Tangente Hiperbólica (tanh)</h2>
<p>La función <strong>tanh</strong> es similar a la sigmoide pero ofrece salidas entre -1 y 1.</p>
<ul>
<li><strong>Función de activación</strong>: <span class="math inline">\(tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\)</span></li>
<li><strong>Salida</strong>: Continua entre -1 y 1.</li>
<li><strong>Usos principales</strong>: Redes recurrentes y algunas redes convolucionales.</li>
</ul>
<p><strong>Arquitectura de una Red con tanh</strong>:</p>

<img data-src="tanh_network_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura tanh</p></section>
<section id="redes-neuronales-convolucionales-cnns" class="slide level2">
<h2>Redes Neuronales Convolucionales (CNNs)</h2>
<p>Las <strong>redes neuronales convolucionales (CNNs)</strong> son ampliamente utilizadas para problemas de visión por computadora.</p>
<ul>
<li><strong>Arquitectura</strong>: Compuesta por capas de convolución, pooling y fully connected.</li>
<li><strong>Función de activación</strong>: ReLU es la más común.</li>
<li><strong>Usos principales</strong>: Clasificación de imágenes, detección de objetos.</li>
</ul>
<p><strong>Arquitectura de una CNN</strong>:</p>

<img data-src="cnn_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura CNN</p></section>
<section id="redes-neuronales-recurrentes-rnns" class="slide level2">
<h2>Redes Neuronales Recurrentes (RNNs)</h2>
<p>Las <strong>redes neuronales recurrentes (RNNs)</strong> son efectivas para problemas secuenciales.</p>
<ul>
<li><strong>Arquitectura</strong>: Los nodos tienen conexiones hacia adelante y hacia atrás, lo que permite tener “memoria”.</li>
<li><strong>Función de activación</strong>: <strong>tanh</strong> y <strong>sigmoide</strong>.</li>
<li><strong>Usos principales</strong>: Procesamiento de lenguaje natural, series temporales.</li>
</ul>
<p><strong>Arquitectura de una RNN</strong>:</p>

<img data-src="rnn_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura RNN</p></section>
<section id="redes-de-memoria-a-largo-plazo-lstm" class="slide level2">
<h2>Redes de Memoria a Largo Plazo (LSTM)</h2>
<p>Las <strong>LSTM (Long Short-Term Memory)</strong> son un tipo especial de RNN que pueden aprender dependencias a largo plazo.</p>
<ul>
<li><strong>Arquitectura</strong>: Incluyen “celdas de memoria” que permiten almacenar información durante largos periodos.</li>
<li><strong>Función de activación</strong>: <strong>tanh</strong> y <strong>sigmoide</strong>.</li>
<li><strong>Usos principales</strong>: Análisis de secuencias largas.</li>
</ul>
<p><strong>Arquitectura de una LSTM</strong>:</p>

<img data-src="lstm_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura LSTM</p></section>
<section id="redes-de-retroalimentación-feedback-networks" class="slide level2">
<h2>Redes de Retroalimentación (Feedback Networks)</h2>
<p>Estas redes permiten que las salidas de ciertas capas alimenten a las capas anteriores.</p>
<ul>
<li><strong>Función de activación</strong>: <strong>sigmoide</strong>, <strong>tanh</strong>, y a veces <strong>ReLU</strong>.</li>
<li><strong>Usos principales</strong>: Análisis de datos donde las salidas deben influir en las entradas anteriores.</li>
</ul>
<p><strong>Arquitectura de una Red de Retroalimentación</strong>:</p>

<img data-src="feedback_network_image.png" class="r-stretch quarto-figure-center"><p class="caption">Arquitectura Feedback</p></section>
<section id="comparación-de-redes-neuronales-y-funciones-de-activación" class="slide level2">
<h2>Comparación de Redes Neuronales y Funciones de Activación</h2>
<table class="caption-top">
<colgroup>
<col style="width: 23%">
<col style="width: 14%">
<col style="width: 23%">
<col style="width: 24%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Red Neuronal / Función de Activación</strong></th>
<th><strong>Salida</strong></th>
<th><strong>Función de Activación</strong></th>
<th><strong>Usos Principales</strong></th>
<th><strong>Entrada</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Perceptrón</strong></td>
<td>Binaria (0 o 1)</td>
<td>Función escalón</td>
<td>Clasificación binaria</td>
<td>Binaria</td>
</tr>
<tr class="even">
<td><strong>Sigmoide</strong></td>
<td>Continua (0 a 1)</td>
<td><span class="math inline">\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</span></td>
<td>Clasificación probabilística</td>
<td>Numérica continua</td>
</tr>
<tr class="odd">
<td><strong>ReLU (Rectificador Lineal Unitario)</strong></td>
<td><span class="math inline">\(max(0, z)\)</span></td>
<td><span class="math inline">\(ReLU(z) = max(0, z)\)</span></td>
<td>Redes profundas y convolucionales</td>
<td>Numérica continua</td>
</tr>
<tr class="even">
<td><strong>tanh (Tangente Hiperbólica)</strong></td>
<td>Continua (-1 a 1)</td>
<td><span class="math inline">\(tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\)</span></td>
<td>Redes recurrentes y algunas convolucionales</td>
<td>Numérica continua</td>
</tr>
</tbody>
</table>
<aside class="notes">
Esta tabla muestra las diferencias entre los tipos de redes neuronales y las funciones de activación que utilizan.
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="introducción-al-backpropagation" class="slide level2">
<h2>Introducción al Backpropagation</h2>
<p>El algoritmo de <strong>backpropagation</strong> se utiliza para ajustar los pesos de una red neuronal minimizando el error entre la salida esperada y la salida obtenida.</p>
<h3 id="por-qué-es-importante-backpropagation">¿Por qué es Importante Backpropagation?</h3>
<ul>
<li>Permite a las redes neuronales aprender de los datos y mejorar sus predicciones.</li>
<li>Optimiza los pesos para minimizar el error a través de un proceso iterativo.</li>
</ul>
</section>
<section id="ciclo-completo-de-backpropagation" class="slide level2">
<h2>Ciclo Completo de Backpropagation</h2>
<ol type="1">
<li><strong>Forward Propagation</strong>: Se calcula la salida.</li>
<li><strong>Cálculo del Error</strong>: Se mide el error entre la salida predicha y la real.</li>
<li><strong>Backward Propagation</strong>: Se ajustan los pesos propagando el error hacia atrás.</li>
<li><strong>Actualización de Pesos</strong>: Los pesos se ajustan utilizando el gradiente de la función de pérdida.</li>
</ol>
</section>
<section id="ajuste-de-pesos-en-una-red-neuronal" class="slide level2">
<h2>Ajuste de Pesos en una Red Neuronal</h2>
<ul>
<li>Cada neurona realiza una suma ponderada de sus entradas: <span class="math display">\[
z = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b
\]</span></li>
<li>La salida de la neurona se obtiene aplicando una función de activación: <span class="math display">\[
y = f(z)
\]</span></li>
</ul>
</section>
<section id="función-de-pérdida-y-el-gradiente" class="slide level2">
<h2>Función de Pérdida y el Gradiente</h2>
<ul>
<li>La función de pérdida mide qué tan lejos está la predicción de la salida correcta: <span class="math display">\[
L = \frac{1}{2} (y_{\text{pred}} - y_{\text{real}})^2
\]</span></li>
<li>Los pesos se ajustan utilizando el descenso de gradiente: <span class="math display">\[
w_i(t+1) = w_i(t) - \eta \frac{\partial L}{\partial w_i}
\]</span></li>
</ul>
</section>
<section id="ecuación-diferencial-en-backpropagation" class="slide level2">
<h2>Ecuación Diferencial en Backpropagation</h2>
<ul>
<li>El ajuste de los pesos sigue una ecuación diferencial: <span class="math display">\[
\frac{d w_i}{d t} = - \frac{\partial L}{\partial w_i}
\]</span></li>
</ul>
</section></section>
<section>
<section id="ejemplo" class="title-slide slide level1 center">
<h1>Ejemplo</h1>
<ul>
<li><p>Entrada: <span class="math inline">\(x_1 = 0.5\)</span>, <span class="math inline">\(x_2 = 0.1\)</span></p></li>
<li><p>Salida esperada: <span class="math inline">\(y_{\text{esperado}} = 1\)</span></p></li>
<li><p>Pesos iniciales:</p>
<ul>
<li><span class="math inline">\(w_{11}^{(1)} = 0.4\)</span>, <span class="math inline">\(w_{12}^{(1)} = 0.2\)</span></li>
<li><span class="math inline">\(w_{21}^{(1)} = 0.1\)</span>, <span class="math inline">\(w_{22}^{(1)} = 0.3\)</span></li>
<li><span class="math inline">\(w_1^{(2)} = 0.6\)</span>, <span class="math inline">\(w_2^{(2)} = 0.5\)</span></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li>Tasa de aprendizaje: <span class="math inline">\(\eta = 0.1\)</span></li>
</ul>
</section>
<section id="paso-1-forward-propagation" class="slide level2">
<h2>Paso 1: Forward Propagation</h2>
<p><strong>Cálculo de las entradas a las neuronas ocultas</strong>:</p>
<p>Para la neurona oculta 1:</p>
<p><span class="math display">\[
z_1 = w_{11}^{(1)} \cdot x_1 + w_{12}^{(1)} \cdot x_2 = (0.4 \cdot 0.5) + (0.2 \cdot 0.1) = 0.22
\]</span></p>
<p>Para la neurona oculta 2:</p>
<p><span class="math display">\[
z_2 = w_{21}^{(1)} \cdot x_1 + w_{22}^{(1)} \cdot x_2 = (0.1 \cdot 0.5) + (0.3 \cdot 0.1) = 0.08
\]</span></p>
</section>
<section id="función-de-activación-sigmoide" class="slide level2">
<h2>Función de Activación Sigmoide</h2>
<p>Aplicando la función de activación sigmoide a las neuronas ocultas:</p>
<p>Para la neurona oculta 1:</p>
<p><span class="math display">\[
a_1 = \frac{1}{1 + e^{-z_1}} = \frac{1}{1 + e^{-0.22}} \approx 0.554
\]</span></p>
<p>Para la neurona oculta 2:</p>
<p><span class="math display">\[
a_2 = \frac{1}{1 + e^{-z_2}} = \frac{1}{1 + e^{-0.08}} \approx 0.520
\]</span></p>
</section>
<section id="entrada-a-la-neurona-de-salida" class="slide level2">
<h2>Entrada a la Neurona de Salida</h2>
<p><span class="math display">\[
z_{\text{salida}} = w_1^{(2)} \cdot a_1 + w_2^{(2)} \cdot a_2 = (0.6 \cdot 0.554) + (0.5 \cdot 0.520) \approx 0.612
\]</span></p>
<p>Aplicando la función de activación sigmoide a la neurona de salida:</p>
<p><span class="math display">\[
a_{\text{salida}} = \frac{1}{1 + e^{-z_{\text{salida}}}} = \frac{1}{1 + e^{-0.612}} \approx 0.648
\]</span></p>
</section>
<section id="paso-2-cálculo-del-error" class="slide level2">
<h2>Paso 2: Cálculo del Error</h2>
<p>El error en la salida es:</p>
<p><span class="math display">\[
\text{Error} = y_{\text{esperado}} - a_{\text{salida}} = 1 - 0.648 = 0.352
\]</span></p>
</section>
<section id="paso-3-backpropagation" class="slide level2">
<h2>Paso 3: Backpropagation</h2>
<h3 id="cálculo-del-gradiente-de-la-neurona-de-salida">Cálculo del gradiente de la neurona de salida:</h3>
<p>La derivada de la función sigmoide es:</p>
<p><span class="math display">\[
\delta_{\text{salida}} = a_{\text{salida}} \cdot (1 - a_{\text{salida}}) \cdot \text{Error} = 0.648 \cdot (1 - 0.648) \cdot 0.352 \approx 0.080
\]</span></p>
</section>
<section id="actualización-de-los-pesos-salida-a-ocultas" class="slide level2">
<h2>Actualización de los Pesos (Salida a Ocultas)</h2>
<p>Actualizar los pesos entre las neuronas ocultas y la neurona de salida:</p>
<p>Para <span class="math inline">\(w_1^{(2)}\)</span>:</p>
<p><span class="math display">\[
w_1^{(2)} = w_1^{(2)} + \eta \cdot \delta_{\text{salida}} \cdot a_1 = 0.6 + 0.1 \cdot 0.080 \cdot 0.554 \approx 0.604
\]</span></p>
<p>Para <span class="math inline">\(w_2^{(2)}\)</span>:</p>
<p><span class="math display">\[
w_2^{(2)} = w_2^{(2)} + \eta \cdot \delta_{\text{salida}} \cdot a_2 = 0.5 + 0.1 \cdot 0.080 \cdot 0.520 \approx 0.504
\]</span></p>
</section>
<section id="actualización-de-los-pesos-entradas-a-ocultas" class="slide level2">
<h2>Actualización de los Pesos (Entradas a Ocultas)</h2>
<p>Gradientes de las neuronas ocultas:</p>
<p>Para la neurona oculta 1:</p>
<p><span class="math display">\[
\delta_1 = a_1 \cdot (1 - a_1) \cdot \delta_{\text{salida}} \cdot w_1^{(2)} = 0.554 \cdot (1 - 0.554) \cdot 0.080 \cdot 0.6 \approx 0.011
\]</span></p>
<p>Para la neurona oculta 2:</p>
<p><span class="math display">\[
\delta_2 = a_2 \cdot (1 - a_2) \cdot \delta_{\text{salida}} \cdot w_2^{(2)} = 0.520 \cdot (1 - 0.520) \cdot 0.080 \cdot 0.5 \approx 0.010
\]</span></p>
</section>
<section id="ajuste-final-de-pesos" class="slide level2">
<h2>Ajuste Final de Pesos</h2>
<p>Actualizar los pesos entre las entradas y las neuronas ocultas:</p>
<p>Para <span class="math inline">\(w_{11}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{11}^{(1)} = w_{11}^{(1)} + \eta \cdot \delta_1 \cdot x_1 = 0.4 + 0.1 \cdot 0.011 \cdot 0.5 \approx 0.401
\]</span></p>
<p>Para <span class="math inline">\(w_{12}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{12}^{(1)} = w_{12}^{(1)} + \eta \cdot \delta_1 \cdot x_2 = 0.2 + 0.1 \cdot 0.011 \cdot 0.1 \approx 0.2001
\]</span></p>
<p>Para <span class="math inline">\(w_{21}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{21}^{(1)} = w_{21}^{(1)} + \eta \cdot \delta_2 \cdot x_1 = 0.1 + 0.1 \cdot 0.010 \cdot 0.5 \approx 0.101
\]</span></p>
<p>Para <span class="math inline">\(w_{22}^{(1)}\)</span>:</p>
<p><span class="math display">\[
w_{22}^{(1)} = w_{22}^{(1)} + \eta \cdot \delta_2 \cdot x_2 = 0.3 + 0.1 \cdot 0.010 \cdot 0.1 \approx 0.3001
\]</span></p>
</section>
<section id="resultados" class="slide level2">
<h2>Resultados</h2>
<ul>
<li>Los pesos han sido ajustados después de aplicar el algoritmo de <strong>backpropagation</strong>.</li>
<li>El proceso se repite hasta que el error se minimiza a un nivel aceptable.</li>
</ul>
</section>
<section id="aplicaciones-actuales-de-las-redes-neuronales" class="slide level2">
<h2>Aplicaciones Actuales de las Redes Neuronales</h2>
<h3 id="visión-por-computadora">Visión por Computadora</h3>
<ul>
<li><strong>Reconocimiento de imágenes y objetos</strong>: Clasificación y detección en tiempo real.</li>
<li><strong>Conducción autónoma</strong>: Interpretación del entorno por vehículos sin conductor.</li>
<li><strong>Diagnóstico médico</strong>: Detección de anomalías en imágenes médicas.</li>
</ul>
</section>
<section id="procesamiento-del-lenguaje-natural-nlp" class="slide level2">
<h2>Procesamiento del Lenguaje Natural (NLP)</h2>
<ul>
<li><strong>Traducción automática</strong>: Conversión entre idiomas en tiempo real.</li>
<li><strong>Análisis de sentimiento</strong>: Interpretación de opiniones en redes sociales.</li>
<li><strong>Chatbots y asistentes virtuales</strong>: Interacción humana con sistemas inteligentes.</li>
</ul>
</section>
<section id="generación-de-contenido" class="slide level2">
<h2>Generación de Contenido</h2>
<ul>
<li><strong>Redes Generativas Adversariales (GANs)</strong>:
<ul>
<li>Creación de imágenes, música y texto artificiales.</li>
</ul></li>
<li><strong>Deepfakes</strong>: Síntesis de videos y audios realistas pero falsos.</li>
</ul>
</section>
<section id="otros-campos-de-aplicación" class="slide level2">
<h2>Otros Campos de Aplicación</h2>
<ul>
<li><strong>Finanzas</strong>: Predicción de mercados y detección de fraudes.</li>
<li><strong>Agricultura</strong>: Monitoreo de cultivos y optimización de recursos.</li>
<li><strong>Ciencias Ambientales</strong>: Modelado climático y predicción de desastres naturales.</li>
</ul>
</section>
<section id="conclusiones" class="slide level2">
<h2>Conclusiones</h2>
<ul>
<li><strong>Evolución constante</strong>: Las redes neuronales siguen avanzando, impulsadas por nuevos algoritmos y mayor poder computacional.</li>
<li><strong>Amplia aplicabilidad</strong>: Su capacidad para abordar problemas complejos las hace indispensables en múltiples industrias.</li>
<li><strong>Desafíos futuros</strong>:
<ul>
<li>Interpretabilidad de modelos.</li>
<li>Eficiencia energética y computacional.</li>
<li>Ética y sesgos en inteligencia artificial.</li>
</ul></li>
</ul>
</section>
<section id="conclusión-de-la-clase" class="slide level2">
<h2>Conclusión de la Clase</h2>
<p>En conclusión, hemos explorado los conceptos fundamentales de las redes neuronales, desde su origen hasta sus aplicaciones actuales en diversos campos. El aprendizaje profundo ha transformado la manera en que abordamos problemas complejos, y su evolución continúa abriendo nuevas oportunidades y desafíos. Es esencial mantenernos actualizados y considerar las implicaciones éticas y sociales al desarrollar y aplicar estas tecnologías.</p>
</section>
<section id="referencias" class="slide level2">
<h2>Referencias</h2>
<ol type="1">
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A.</strong> (2016). <em>Deep Learning</em>. MIT Press.</li>
<li><strong>Nielsen, M. A.</strong> (2015). <em>Neural Networks and Deep Learning</em>. Disponible en <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a>.</li>
<li><strong>Chollet, F.</strong> (2018). <em>Deep Learning with Python</em>. Manning Publications.</li>
</ol>
</section>
<section class="slide level2">

<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Clase Redes Neuronales_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>